{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/student/.local/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/student/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/student/.local/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/student/.local/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/student/.local/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: requests in /home/student/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: pandas in /home/student/.local/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/student/.local/lib/python3.10/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/student/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/student/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub in /home/student/.local/lib/python3.10/site-packages (0.21.4)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/student/.local/lib/python3.10/site-packages (from huggingface_hub) (4.10.0)\n",
      "Requirement already satisfied: requests in /home/student/.local/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/student/.local/lib/python3.10/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/student/.local/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/student/.local/lib/python3.10/site-packages (from huggingface_hub) (24.0)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: pandas in /home/student/.local/lib/python3.10/site-packages (from evaluate) (2.2.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (2024.2.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: packaging in /home/student/.local/lib/python3.10/site-packages (from evaluate) (24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (0.21.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/student/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/.local/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/.local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/.local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/student/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "\u001b[33m  WARNING: The script evaluate-cli is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.3\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/student/.local/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers datasets peft accelerate \n",
    "!pip install huggingface_hub scikit-learn\n",
    "!pip install evaluate\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687d08ccea304440a36957511b1ec820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 359k/359k [00:00<00:00, 1.38MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3690649b4c34158be7428501e06dcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, AutoPeftModelForSequenceClassification, TaskType\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "import json\n",
    "from datasets import DatasetDict, load_metric\n",
    "\n",
    "# aka big bang\n",
    "planck0 = time.time()\n",
    "\n",
    "def p(text, width=80):\n",
    "    print(\"\\n\"*3+\"=\"*width+\"\\n\"+text.upper().center(width)+\"\\n\"+\"=\"*width)\n",
    "    \n",
    "def secToHuman(elapsed_time):\n",
    "    hours, rem = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    # return hours, minutes, seconds\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{seconds:.2f}\"    \n",
    "\n",
    "# variables\n",
    "CHECKPOINTS = \"./checkpoints\"\n",
    "PEFT_MODEL = \"./peft_model\"\n",
    "\n",
    "resultset = []\n",
    "\n",
    "label_names = [\"not spam\", \"spam\"]\n",
    "id2label = {idx: label for idx, label in enumerate(label_names)}\n",
    "label2id = {label: idx for idx, label in enumerate(label_names)}\n",
    "model = None\n",
    "peft_model = None\n",
    "tokenizer = None\n",
    "tokenized_ds = {} \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "###############################################################################\n",
    "# Loading and Evaluating a Foundation Model\n",
    "###############################################################################\n",
    "split = ['train', 'test']\n",
    "\n",
    "raw_dataset = load_dataset(\"sms_spam\")\n",
    "full_dataset = raw_dataset['train'].train_test_split(test_size=0.2, seed=42, shuffle=True)\n",
    "\n",
    "# dataset =  DatasetDict({\"train\": full_dataset[\"train\"].shuffle(seed=42).select(range(1000)),  # Keep only 1000 samples\n",
    "#             \"test\":  full_dataset[\"test\"].shuffle(seed=42).select(range(200))  # Keep only 200 samples\n",
    "#             })\n",
    "dataset =  DatasetDict({\"train\": full_dataset[\"train\"].shuffle(seed=42),  \n",
    "            \"test\":  full_dataset[\"test\"].shuffle(seed=42)\n",
    "            })\n",
    "\n",
    "print(\"Dataset loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d93381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt2_compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(logits, tuple):  # Ensure it's not a dictionary\n",
    "        logits = logits[0]\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    global tokenizer\n",
    "    return tokenizer(examples[\"sms\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gpt2_model(dataset, with_train=False):\n",
    "    global tokenizer\n",
    "    # Load GPT-2 tokenizer and model\n",
    "    # from transformers import BitsAndBytesConfig\n",
    "    # bnb_config = BitsAndBytesConfig(load_in_8bit=True)  # 8-bit quantization\n",
    "\n",
    "    model_name = \"gpt2\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=2, id2label=id2label, label2id=label2id,\n",
    "    #     quantization_config=bnb_config\n",
    "    ).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # GPT-2 doesn't have a padding token, so use eos_token and set padding_side to left\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"  # Ensure left padding for GPT-2\n",
    "\n",
    "    for s in split:\n",
    "        tokenized_ds[s] = dataset[s].map(tokenize_fn, batched=True)\n",
    "\n",
    "    tokenized_ds[\"train\"] = tokenized_ds[\"train\"].map(\n",
    "        lambda e: {'labels': e['label']},  \n",
    "        batched=True,\n",
    "        remove_columns=['label']\n",
    "    )\n",
    "    tokenized_ds[\"test\"] = tokenized_ds[\"test\"].map(\n",
    "        lambda e: {'labels': e['label']},  \n",
    "        batched=True,\n",
    "        remove_columns=['label']\n",
    "    )\n",
    "\n",
    "    tokenized_ds[\"train\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    tokenized_ds[\"test\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    print(\"===========================================================\")\n",
    "    print(tokenized_ds[\"train\"].column_names)\n",
    "    print(\"===========================================================\")\n",
    "\n",
    "\n",
    "    ###############################################################################\n",
    "    # Load model and freeze base parameters\n",
    "    ###############################################################################\n",
    "\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.resize_token_embeddings(len(tokenizer))  # Adjust embedding size for new tokens\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"score\" not in name:  # Keep classification head trainable\n",
    "            param.requires_grad = True\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.requires_grad)\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=CHECKPOINTS, \n",
    "            resume_from_checkpoint=True,\n",
    "            learning_rate=2e-5, \n",
    "            per_device_train_batch_size=16, \n",
    "            per_device_eval_batch_size=16, \n",
    "            num_train_epochs=2, \n",
    "            weight_decay=0.01, \n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\", \n",
    "            metric_for_best_model=\"accuracy\",  # Change from \"eval_loss\" to \"accuracy\"\n",
    "            load_best_model_at_end=True, \n",
    "        ),\n",
    "        train_dataset=tokenized_ds[\"train\"],\n",
    "        eval_dataset=tokenized_ds[\"test\"], \n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\"),\n",
    "        compute_metrics=gpt2_compute_metrics, \n",
    "    )\n",
    "\n",
    "    metrics = trainer.evaluate()\n",
    "    result = f\"GPT2 Evaluation metrics before everything: {metrics}\"\n",
    "    if (with_train):\n",
    "        trainer.train()\n",
    "        metrics = trainer.evaluate()\n",
    "        result+=f\"\\nEvaluation metrics after gpt2 train: {metrics}\"\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4301c916e94ddb8be8fdc67515b97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d068b08fe04196943ed841ad73f48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ab824b4e5548028c42386c794495b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46255f9aea604b04b37b6a7e459d8d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451072a571a349acba2d38428ddd5954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd66293a9107457594785aa86ca4009b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ceb7dc8d5ed4132a577a658333da7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab44385283f47489397c16eefaddf5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7349a505c4ff44d28cc8ad7eb80de82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158c891ec00845c0b31b79812e47f4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "['sms', 'input_ids', 'attention_mask', 'labels']\n",
      "===========================================================\n",
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n",
      "transformer.wte.weight True\n",
      "transformer.wpe.weight True\n",
      "transformer.h.0.ln_1.weight True\n",
      "transformer.h.0.ln_1.bias True\n",
      "transformer.h.0.attn.c_attn.weight True\n",
      "transformer.h.0.attn.c_attn.bias True\n",
      "transformer.h.0.attn.c_proj.weight True\n",
      "transformer.h.0.attn.c_proj.bias True\n",
      "transformer.h.0.ln_2.weight True\n",
      "transformer.h.0.ln_2.bias True\n",
      "transformer.h.0.mlp.c_fc.weight True\n",
      "transformer.h.0.mlp.c_fc.bias True\n",
      "transformer.h.0.mlp.c_proj.weight True\n",
      "transformer.h.0.mlp.c_proj.bias True\n",
      "transformer.h.1.ln_1.weight True\n",
      "transformer.h.1.ln_1.bias True\n",
      "transformer.h.1.attn.c_attn.weight True\n",
      "transformer.h.1.attn.c_attn.bias True\n",
      "transformer.h.1.attn.c_proj.weight True\n",
      "transformer.h.1.attn.c_proj.bias True\n",
      "transformer.h.1.ln_2.weight True\n",
      "transformer.h.1.ln_2.bias True\n",
      "transformer.h.1.mlp.c_fc.weight True\n",
      "transformer.h.1.mlp.c_fc.bias True\n",
      "transformer.h.1.mlp.c_proj.weight True\n",
      "transformer.h.1.mlp.c_proj.bias True\n",
      "transformer.h.2.ln_1.weight True\n",
      "transformer.h.2.ln_1.bias True\n",
      "transformer.h.2.attn.c_attn.weight True\n",
      "transformer.h.2.attn.c_attn.bias True\n",
      "transformer.h.2.attn.c_proj.weight True\n",
      "transformer.h.2.attn.c_proj.bias True\n",
      "transformer.h.2.ln_2.weight True\n",
      "transformer.h.2.ln_2.bias True\n",
      "transformer.h.2.mlp.c_fc.weight True\n",
      "transformer.h.2.mlp.c_fc.bias True\n",
      "transformer.h.2.mlp.c_proj.weight True\n",
      "transformer.h.2.mlp.c_proj.bias True\n",
      "transformer.h.3.ln_1.weight True\n",
      "transformer.h.3.ln_1.bias True\n",
      "transformer.h.3.attn.c_attn.weight True\n",
      "transformer.h.3.attn.c_attn.bias True\n",
      "transformer.h.3.attn.c_proj.weight True\n",
      "transformer.h.3.attn.c_proj.bias True\n",
      "transformer.h.3.ln_2.weight True\n",
      "transformer.h.3.ln_2.bias True\n",
      "transformer.h.3.mlp.c_fc.weight True\n",
      "transformer.h.3.mlp.c_fc.bias True\n",
      "transformer.h.3.mlp.c_proj.weight True\n",
      "transformer.h.3.mlp.c_proj.bias True\n",
      "transformer.h.4.ln_1.weight True\n",
      "transformer.h.4.ln_1.bias True\n",
      "transformer.h.4.attn.c_attn.weight True\n",
      "transformer.h.4.attn.c_attn.bias True\n",
      "transformer.h.4.attn.c_proj.weight True\n",
      "transformer.h.4.attn.c_proj.bias True\n",
      "transformer.h.4.ln_2.weight True\n",
      "transformer.h.4.ln_2.bias True\n",
      "transformer.h.4.mlp.c_fc.weight True\n",
      "transformer.h.4.mlp.c_fc.bias True\n",
      "transformer.h.4.mlp.c_proj.weight True\n",
      "transformer.h.4.mlp.c_proj.bias True\n",
      "transformer.h.5.ln_1.weight True\n",
      "transformer.h.5.ln_1.bias True\n",
      "transformer.h.5.attn.c_attn.weight True\n",
      "transformer.h.5.attn.c_attn.bias True\n",
      "transformer.h.5.attn.c_proj.weight True\n",
      "transformer.h.5.attn.c_proj.bias True\n",
      "transformer.h.5.ln_2.weight True\n",
      "transformer.h.5.ln_2.bias True\n",
      "transformer.h.5.mlp.c_fc.weight True\n",
      "transformer.h.5.mlp.c_fc.bias True\n",
      "transformer.h.5.mlp.c_proj.weight True\n",
      "transformer.h.5.mlp.c_proj.bias True\n",
      "transformer.h.6.ln_1.weight True\n",
      "transformer.h.6.ln_1.bias True\n",
      "transformer.h.6.attn.c_attn.weight True\n",
      "transformer.h.6.attn.c_attn.bias True\n",
      "transformer.h.6.attn.c_proj.weight True\n",
      "transformer.h.6.attn.c_proj.bias True\n",
      "transformer.h.6.ln_2.weight True\n",
      "transformer.h.6.ln_2.bias True\n",
      "transformer.h.6.mlp.c_fc.weight True\n",
      "transformer.h.6.mlp.c_fc.bias True\n",
      "transformer.h.6.mlp.c_proj.weight True\n",
      "transformer.h.6.mlp.c_proj.bias True\n",
      "transformer.h.7.ln_1.weight True\n",
      "transformer.h.7.ln_1.bias True\n",
      "transformer.h.7.attn.c_attn.weight True\n",
      "transformer.h.7.attn.c_attn.bias True\n",
      "transformer.h.7.attn.c_proj.weight True\n",
      "transformer.h.7.attn.c_proj.bias True\n",
      "transformer.h.7.ln_2.weight True\n",
      "transformer.h.7.ln_2.bias True\n",
      "transformer.h.7.mlp.c_fc.weight True\n",
      "transformer.h.7.mlp.c_fc.bias True\n",
      "transformer.h.7.mlp.c_proj.weight True\n",
      "transformer.h.7.mlp.c_proj.bias True\n",
      "transformer.h.8.ln_1.weight True\n",
      "transformer.h.8.ln_1.bias True\n",
      "transformer.h.8.attn.c_attn.weight True\n",
      "transformer.h.8.attn.c_attn.bias True\n",
      "transformer.h.8.attn.c_proj.weight True\n",
      "transformer.h.8.attn.c_proj.bias True\n",
      "transformer.h.8.ln_2.weight True\n",
      "transformer.h.8.ln_2.bias True\n",
      "transformer.h.8.mlp.c_fc.weight True\n",
      "transformer.h.8.mlp.c_fc.bias True\n",
      "transformer.h.8.mlp.c_proj.weight True\n",
      "transformer.h.8.mlp.c_proj.bias True\n",
      "transformer.h.9.ln_1.weight True\n",
      "transformer.h.9.ln_1.bias True\n",
      "transformer.h.9.attn.c_attn.weight True\n",
      "transformer.h.9.attn.c_attn.bias True\n",
      "transformer.h.9.attn.c_proj.weight True\n",
      "transformer.h.9.attn.c_proj.bias True\n",
      "transformer.h.9.ln_2.weight True\n",
      "transformer.h.9.ln_2.bias True\n",
      "transformer.h.9.mlp.c_fc.weight True\n",
      "transformer.h.9.mlp.c_fc.bias True\n",
      "transformer.h.9.mlp.c_proj.weight True\n",
      "transformer.h.9.mlp.c_proj.bias True\n",
      "transformer.h.10.ln_1.weight True\n",
      "transformer.h.10.ln_1.bias True\n",
      "transformer.h.10.attn.c_attn.weight True\n",
      "transformer.h.10.attn.c_attn.bias True\n",
      "transformer.h.10.attn.c_proj.weight True\n",
      "transformer.h.10.attn.c_proj.bias True\n",
      "transformer.h.10.ln_2.weight True\n",
      "transformer.h.10.ln_2.bias True\n",
      "transformer.h.10.mlp.c_fc.weight True\n",
      "transformer.h.10.mlp.c_fc.bias True\n",
      "transformer.h.10.mlp.c_proj.weight True\n",
      "transformer.h.10.mlp.c_proj.bias True\n",
      "transformer.h.11.ln_1.weight True\n",
      "transformer.h.11.ln_1.bias True\n",
      "transformer.h.11.attn.c_attn.weight True\n",
      "transformer.h.11.attn.c_attn.bias True\n",
      "transformer.h.11.attn.c_proj.weight True\n",
      "transformer.h.11.attn.c_proj.bias True\n",
      "transformer.h.11.ln_2.weight True\n",
      "transformer.h.11.ln_2.bias True\n",
      "transformer.h.11.mlp.c_fc.weight True\n",
      "transformer.h.11.mlp.c_fc.bias True\n",
      "transformer.h.11.mlp.c_proj.weight True\n",
      "transformer.h.11.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n",
      "score.weight True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 04:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='558' max='558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [558/558 08:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.069521</td>\n",
       "      <td>0.985650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.144600</td>\n",
       "      <td>0.072138</td>\n",
       "      <td>0.984753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./checkpoints/checkpoint-279 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./checkpoints/checkpoint-558 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Run GPT2 Evaluation and Traing', '00:08:50.99', \"GPT2 Evaluation metrics before everything: {'eval_loss': 0.4561626613140106, 'eval_accuracy': 0.7793721973094171, 'eval_runtime': 17.0024, 'eval_samples_per_second': 65.579, 'eval_steps_per_second': 4.117}\\nEvaluation metrics after gpt2 train: {'eval_loss': 0.06952129304409027, 'eval_accuracy': 0.9856502242152466, 'eval_runtime': 18.3855, 'eval_samples_per_second': 60.645, 'eval_steps_per_second': 3.807, 'epoch': 2.0}\"]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model, result = evaluate_gpt2_model(dataset, True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = secToHuman(end_time - start_time)\n",
    "r = [\"Run GPT2 Evaluation and Traing\", elapsed_time, result]\n",
    "resultset.append(r)\n",
    "print(f\"{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf0314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962564cd68494ac4b7d962e2a949db73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469302b09117468bbd5ab718fd073171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "['sms', 'input_ids', 'attention_mask', 'labels']\n",
      "===========================================================\n",
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n",
      "transformer.wte.weight True\n",
      "transformer.wpe.weight True\n",
      "transformer.h.0.ln_1.weight True\n",
      "transformer.h.0.ln_1.bias True\n",
      "transformer.h.0.attn.c_attn.weight True\n",
      "transformer.h.0.attn.c_attn.bias True\n",
      "transformer.h.0.attn.c_proj.weight True\n",
      "transformer.h.0.attn.c_proj.bias True\n",
      "transformer.h.0.ln_2.weight True\n",
      "transformer.h.0.ln_2.bias True\n",
      "transformer.h.0.mlp.c_fc.weight True\n",
      "transformer.h.0.mlp.c_fc.bias True\n",
      "transformer.h.0.mlp.c_proj.weight True\n",
      "transformer.h.0.mlp.c_proj.bias True\n",
      "transformer.h.1.ln_1.weight True\n",
      "transformer.h.1.ln_1.bias True\n",
      "transformer.h.1.attn.c_attn.weight True\n",
      "transformer.h.1.attn.c_attn.bias True\n",
      "transformer.h.1.attn.c_proj.weight True\n",
      "transformer.h.1.attn.c_proj.bias True\n",
      "transformer.h.1.ln_2.weight True\n",
      "transformer.h.1.ln_2.bias True\n",
      "transformer.h.1.mlp.c_fc.weight True\n",
      "transformer.h.1.mlp.c_fc.bias True\n",
      "transformer.h.1.mlp.c_proj.weight True\n",
      "transformer.h.1.mlp.c_proj.bias True\n",
      "transformer.h.2.ln_1.weight True\n",
      "transformer.h.2.ln_1.bias True\n",
      "transformer.h.2.attn.c_attn.weight True\n",
      "transformer.h.2.attn.c_attn.bias True\n",
      "transformer.h.2.attn.c_proj.weight True\n",
      "transformer.h.2.attn.c_proj.bias True\n",
      "transformer.h.2.ln_2.weight True\n",
      "transformer.h.2.ln_2.bias True\n",
      "transformer.h.2.mlp.c_fc.weight True\n",
      "transformer.h.2.mlp.c_fc.bias True\n",
      "transformer.h.2.mlp.c_proj.weight True\n",
      "transformer.h.2.mlp.c_proj.bias True\n",
      "transformer.h.3.ln_1.weight True\n",
      "transformer.h.3.ln_1.bias True\n",
      "transformer.h.3.attn.c_attn.weight True\n",
      "transformer.h.3.attn.c_attn.bias True\n",
      "transformer.h.3.attn.c_proj.weight True\n",
      "transformer.h.3.attn.c_proj.bias True\n",
      "transformer.h.3.ln_2.weight True\n",
      "transformer.h.3.ln_2.bias True\n",
      "transformer.h.3.mlp.c_fc.weight True\n",
      "transformer.h.3.mlp.c_fc.bias True\n",
      "transformer.h.3.mlp.c_proj.weight True\n",
      "transformer.h.3.mlp.c_proj.bias True\n",
      "transformer.h.4.ln_1.weight True\n",
      "transformer.h.4.ln_1.bias True\n",
      "transformer.h.4.attn.c_attn.weight True\n",
      "transformer.h.4.attn.c_attn.bias True\n",
      "transformer.h.4.attn.c_proj.weight True\n",
      "transformer.h.4.attn.c_proj.bias True\n",
      "transformer.h.4.ln_2.weight True\n",
      "transformer.h.4.ln_2.bias True\n",
      "transformer.h.4.mlp.c_fc.weight True\n",
      "transformer.h.4.mlp.c_fc.bias True\n",
      "transformer.h.4.mlp.c_proj.weight True\n",
      "transformer.h.4.mlp.c_proj.bias True\n",
      "transformer.h.5.ln_1.weight True\n",
      "transformer.h.5.ln_1.bias True\n",
      "transformer.h.5.attn.c_attn.weight True\n",
      "transformer.h.5.attn.c_attn.bias True\n",
      "transformer.h.5.attn.c_proj.weight True\n",
      "transformer.h.5.attn.c_proj.bias True\n",
      "transformer.h.5.ln_2.weight True\n",
      "transformer.h.5.ln_2.bias True\n",
      "transformer.h.5.mlp.c_fc.weight True\n",
      "transformer.h.5.mlp.c_fc.bias True\n",
      "transformer.h.5.mlp.c_proj.weight True\n",
      "transformer.h.5.mlp.c_proj.bias True\n",
      "transformer.h.6.ln_1.weight True\n",
      "transformer.h.6.ln_1.bias True\n",
      "transformer.h.6.attn.c_attn.weight True\n",
      "transformer.h.6.attn.c_attn.bias True\n",
      "transformer.h.6.attn.c_proj.weight True\n",
      "transformer.h.6.attn.c_proj.bias True\n",
      "transformer.h.6.ln_2.weight True\n",
      "transformer.h.6.ln_2.bias True\n",
      "transformer.h.6.mlp.c_fc.weight True\n",
      "transformer.h.6.mlp.c_fc.bias True\n",
      "transformer.h.6.mlp.c_proj.weight True\n",
      "transformer.h.6.mlp.c_proj.bias True\n",
      "transformer.h.7.ln_1.weight True\n",
      "transformer.h.7.ln_1.bias True\n",
      "transformer.h.7.attn.c_attn.weight True\n",
      "transformer.h.7.attn.c_attn.bias True\n",
      "transformer.h.7.attn.c_proj.weight True\n",
      "transformer.h.7.attn.c_proj.bias True\n",
      "transformer.h.7.ln_2.weight True\n",
      "transformer.h.7.ln_2.bias True\n",
      "transformer.h.7.mlp.c_fc.weight True\n",
      "transformer.h.7.mlp.c_fc.bias True\n",
      "transformer.h.7.mlp.c_proj.weight True\n",
      "transformer.h.7.mlp.c_proj.bias True\n",
      "transformer.h.8.ln_1.weight True\n",
      "transformer.h.8.ln_1.bias True\n",
      "transformer.h.8.attn.c_attn.weight True\n",
      "transformer.h.8.attn.c_attn.bias True\n",
      "transformer.h.8.attn.c_proj.weight True\n",
      "transformer.h.8.attn.c_proj.bias True\n",
      "transformer.h.8.ln_2.weight True\n",
      "transformer.h.8.ln_2.bias True\n",
      "transformer.h.8.mlp.c_fc.weight True\n",
      "transformer.h.8.mlp.c_fc.bias True\n",
      "transformer.h.8.mlp.c_proj.weight True\n",
      "transformer.h.8.mlp.c_proj.bias True\n",
      "transformer.h.9.ln_1.weight True\n",
      "transformer.h.9.ln_1.bias True\n",
      "transformer.h.9.attn.c_attn.weight True\n",
      "transformer.h.9.attn.c_attn.bias True\n",
      "transformer.h.9.attn.c_proj.weight True\n",
      "transformer.h.9.attn.c_proj.bias True\n",
      "transformer.h.9.ln_2.weight True\n",
      "transformer.h.9.ln_2.bias True\n",
      "transformer.h.9.mlp.c_fc.weight True\n",
      "transformer.h.9.mlp.c_fc.bias True\n",
      "transformer.h.9.mlp.c_proj.weight True\n",
      "transformer.h.9.mlp.c_proj.bias True\n",
      "transformer.h.10.ln_1.weight True\n",
      "transformer.h.10.ln_1.bias True\n",
      "transformer.h.10.attn.c_attn.weight True\n",
      "transformer.h.10.attn.c_attn.bias True\n",
      "transformer.h.10.attn.c_proj.weight True\n",
      "transformer.h.10.attn.c_proj.bias True\n",
      "transformer.h.10.ln_2.weight True\n",
      "transformer.h.10.ln_2.bias True\n",
      "transformer.h.10.mlp.c_fc.weight True\n",
      "transformer.h.10.mlp.c_fc.bias True\n",
      "transformer.h.10.mlp.c_proj.weight True\n",
      "transformer.h.10.mlp.c_proj.bias True\n",
      "transformer.h.11.ln_1.weight True\n",
      "transformer.h.11.ln_1.bias True\n",
      "transformer.h.11.attn.c_attn.weight True\n",
      "transformer.h.11.attn.c_attn.bias True\n",
      "transformer.h.11.attn.c_proj.weight True\n",
      "transformer.h.11.attn.c_proj.bias True\n",
      "transformer.h.11.ln_2.weight True\n",
      "transformer.h.11.ln_2.bias True\n",
      "transformer.h.11.mlp.c_fc.weight True\n",
      "transformer.h.11.mlp.c_fc.bias True\n",
      "transformer.h.11.mlp.c_proj.weight True\n",
      "transformer.h.11.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n",
      "score.weight True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Run GPT2 Evaluation', '00:00:24.46', \"GPT2 Evaluation metrics before everything: {'eval_loss': 0.6713482737541199, 'eval_accuracy': 0.6098654708520179, 'eval_runtime': 18.8693, 'eval_samples_per_second': 59.091, 'eval_steps_per_second': 3.71}\"]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model, result = evaluate_gpt2_model(dataset, False)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = secToHuman(end_time - start_time)\n",
    "r = [\"Run GPT2 Evaluation\", elapsed_time, result]\n",
    "resultset.append(r)\n",
    "print(f\"{r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Performing Parameter-Efficient Fine-Tuning\n",
    "###############################################################################\n",
    "# tokenizer = AutoTokenizer.from_pretrained(GPT2_FINETUNED_MODEL)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(GPT2_FINETUNED_MODEL, ignore_mismatched_sizes=True).to(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e79f19ac0144ce9aab21a8db673941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fd812bb92a4c579232d8c980273fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 297,984 || all params: 124,737,792 || trainable%: 0.23888830740245906\n",
      "peft model saved\n"
     ]
    }
   ],
   "source": [
    "def lora_compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    print(\"Logits Type:\", type(logits))\n",
    "    print(\"Logits Shape:\", np.array(logits, dtype=object).shape)\n",
    "    print(\"Labels Type:\", type(labels))\n",
    "    print(\"Labels Shape:\", np.array(labels, dtype=object).shape)\n",
    "\n",
    "    # Extract logits if they are inside a tuple\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]  # Take the first element of the tuple\n",
    "\n",
    "    # Ensure logits is a NumPy array\n",
    "    logits = np.array(logits)\n",
    "\n",
    "    # Ensure labels is a NumPy array\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Compute predictions\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = load_metric(\"accuracy\", trust_remote_code=True) \n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "\n",
    "    print(\"Computed Accuracy:\", acc)\n",
    "    return {\"eval_accuracy\": acc}\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "result = []\n",
    "\n",
    "tokenized_ds = dataset.map(\n",
    "    lambda x: tokenizer(x[\"sms\"], padding=\"max_length\", truncation=True, max_length=512),\n",
    "    batched=True\n",
    ")\n",
    "tokenized_ds = tokenized_ds.rename_columns({\"label\": \"labels\"})\n",
    "tokenized_ds[\"train\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_ds[\"test\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(r=8, lora_alpha=16, lora_dropout=0.1, bias=\"none\", task_type=TaskType.SEQ_CLS)\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "peft_model.to(device)\n",
    "\n",
    "peft_model.save_pretrained(PEFT_MODEL)\n",
    "print(\"peft model saved\")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,  # Make sure to pass the PEFT model here\n",
    "    args=TrainingArguments(\n",
    "        output_dir=CHECKPOINTS,\n",
    "        resume_from_checkpoint=True,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=3,\n",
    "        logging_steps=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        metric_for_best_model=\"eval_accuracy\",  \n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        label_names=[\"labels\"],\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\"),\n",
    "    compute_metrics=lora_compute_metrics,\n",
    ")\n",
    "trainer.compute_metrics=lora_compute_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits Type: <class 'numpy.ndarray'>\n",
      "Logits Shape: (1115, 2)\n",
      "Labels Type: <class 'numpy.ndarray'>\n",
      "Labels Shape: (1115,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2890357182.py:22: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy = load_metric(\"accuracy\", trust_remote_code=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797e99ca383b4907aee2c8de7a8c6280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Accuracy: 0.431390134529148\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 07:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits Type: <class 'numpy.ndarray'>\n",
      "Logits Shape: (1115, 2)\n",
      "Labels Type: <class 'numpy.ndarray'>\n",
      "Labels Shape: (1115,)\n",
      "Computed Accuracy: 0.431390134529148\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict, load_metric\n",
    "\n",
    "# Run evaluation manually\n",
    "eval_output = trainer.predict(tokenized_ds[\"test\"])\n",
    "logits = eval_output.predictions\n",
    "labels = eval_output.label_ids  \n",
    "metrics = trainer.evaluate()\n",
    "result.append(f\"Lora Evaluation metrics before training: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sms', 'labels', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1674' max='1674' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1674/1674 21:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.759100</td>\n",
       "      <td>0.336463</td>\n",
       "      <td>0.865471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.307216</td>\n",
       "      <td>0.868161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.296908</td>\n",
       "      <td>0.868161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits Type: <class 'numpy.ndarray'>\n",
      "Logits Shape: (1115, 2)\n",
      "Labels Type: <class 'numpy.ndarray'>\n",
      "Labels Shape: (1115,)\n",
      "Computed Accuracy: 0.8654708520179372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./checkpoints/checkpoint-558 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits Type: <class 'numpy.ndarray'>\n",
      "Logits Shape: (1115, 2)\n",
      "Labels Type: <class 'numpy.ndarray'>\n",
      "Labels Shape: (1115,)\n",
      "Computed Accuracy: 0.8681614349775785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./checkpoints/checkpoint-1116 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits Type: <class 'numpy.ndarray'>\n",
      "Logits Shape: (1115, 2)\n",
      "Labels Type: <class 'numpy.ndarray'>\n",
      "Labels Shape: (1115,)\n",
      "Computed Accuracy: 0.8681614349775785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./checkpoints/checkpoint-1674 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits Type: <class 'numpy.ndarray'>\n",
      "Logits Shape: (1115, 2)\n",
      "Labels Type: <class 'numpy.ndarray'>\n",
      "Labels Shape: (1115,)\n",
      "Computed Accuracy: 0.8681614349775785\n",
      "['Run Lora Evaluation and Traing', '00:23:19.39', [\"Lora Evaluation metrics before training: {'eval_accuracy': 0.431390134529148, 'eval_loss': 0.8402268290519714, 'eval_runtime': 42.4556, 'eval_samples_per_second': 26.263, 'eval_steps_per_second': 3.298}\", \"Lora Evaluation metrics after training: {'eval_accuracy': 0.8681614349775785, 'eval_loss': 0.30721625685691833, 'eval_runtime': 42.5423, 'eval_samples_per_second': 26.209, 'eval_steps_per_second': 3.291, 'epoch': 3.0}\"]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tokenized_ds[\"test\"].column_names)  # Should include \"labels\"\n",
    "trainer.train() # resume_from_checkpoint=CHECKPOINTS+\"/checkpoint-last\")\n",
    "metrics = trainer.evaluate()\n",
    "result.append(f\"Lora Evaluation metrics after training: {metrics}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = secToHuman(end_time - start_time)\n",
    "r = [\"Run Lora Evaluation and Traing\", elapsed_time, result]\n",
    "resultset.append(r)\n",
    "print(f\"{r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft model loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Run Hugging Face Evaluation', '00:00:54.72', [\"Hugging Face Evaluation metrics: {'eval_loss': 0.30721625685691833, 'eval_accuracy': 0.8681614349775785, 'eval_runtime': 49.0418, 'eval_samples_per_second': 22.736, 'eval_steps_per_second': 2.855}\"]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "# Performing Inference with a PEFT Model\n",
    "###############################################################################\n",
    "\n",
    "def hf_compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]  # Extract logits array if it's a tuple\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = load_metric(\"accuracy\", trust_remote_code=True) \n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "start_time = time.time()\n",
    "result = [] \n",
    "NUM_LABELS = 2\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(PEFT_MODEL, ignore_mismatched_sizes=True).to(device)\n",
    "print(\"peft model loaded\")\n",
    "\n",
    "model.to(device)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,  # PEFT model\n",
    "    args=TrainingArguments(\n",
    "        output_dir=CHECKPOINTS, \n",
    "        resume_from_checkpoint=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\", \n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=hf_compute_metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the fine-tuned model on the test set\n",
    "hf_results = trainer.evaluate()\n",
    "result.append(f\"Hugging Face Evaluation metrics: {hf_results}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = secToHuman(end_time - start_time)\n",
    "r = [\"Run Hugging Face Evaluation\", elapsed_time, result]\n",
    "resultset.append(r)\n",
    "print(f\"{r}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "big_crunch = time.time()\n",
    "elapsed_time = secToHuman(big_crunch - planck0)\n",
    "start_d = datetime.fromtimestamp(planck0 / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "end_d = datetime.fromtimestamp(big_crunch / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "r = {\"Runtime Summary\",  elapsed_time, \"\"}\n",
    "resultset.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8ed63_row0_col0, #T_8ed63_row0_col1, #T_8ed63_row0_col2, #T_8ed63_row1_col0, #T_8ed63_row1_col1, #T_8ed63_row1_col2, #T_8ed63_row2_col0, #T_8ed63_row2_col1, #T_8ed63_row2_col2, #T_8ed63_row3_col0, #T_8ed63_row3_col1, #T_8ed63_row3_col2, #T_8ed63_row4_col0, #T_8ed63_row4_col1, #T_8ed63_row4_col2 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8ed63\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8ed63_level0_col0\" class=\"col_heading level0 col0\" >Task</th>\n",
       "      <th id=\"T_8ed63_level0_col1\" class=\"col_heading level0 col1\" >Elapsed Time</th>\n",
       "      <th id=\"T_8ed63_level0_col2\" class=\"col_heading level0 col2\" >Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8ed63_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8ed63_row0_col0\" class=\"data row0 col0\" >Run GPT2 Evaluation and Traing</td>\n",
       "      <td id=\"T_8ed63_row0_col1\" class=\"data row0 col1\" >00:08:50.99</td>\n",
       "      <td id=\"T_8ed63_row0_col2\" class=\"data row0 col2\" >GPT2 Evaluation metrics before everything: {'eval_loss': 0.4561626613140106, 'eval_accuracy': 0.7793721973094171, 'eval_runtime': 17.0024, 'eval_samples_per_second': 65.579, 'eval_steps_per_second': 4.117}\n",
       "Evaluation metrics after gpt2 train: {'eval_loss': 0.06952129304409027, 'eval_accuracy': 0.9856502242152466, 'eval_runtime': 18.3855, 'eval_samples_per_second': 60.645, 'eval_steps_per_second': 3.807, 'epoch': 2.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ed63_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8ed63_row1_col0\" class=\"data row1 col0\" >Run GPT2 Evaluation</td>\n",
       "      <td id=\"T_8ed63_row1_col1\" class=\"data row1 col1\" >00:00:24.46</td>\n",
       "      <td id=\"T_8ed63_row1_col2\" class=\"data row1 col2\" >GPT2 Evaluation metrics before everything: {'eval_loss': 0.6713482737541199, 'eval_accuracy': 0.6098654708520179, 'eval_runtime': 18.8693, 'eval_samples_per_second': 59.091, 'eval_steps_per_second': 3.71}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ed63_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8ed63_row2_col0\" class=\"data row2 col0\" >Run Lora Evaluation and Traing</td>\n",
       "      <td id=\"T_8ed63_row2_col1\" class=\"data row2 col1\" >00:23:19.39</td>\n",
       "      <td id=\"T_8ed63_row2_col2\" class=\"data row2 col2\" >[\"Lora Evaluation metrics before training: {'eval_accuracy': 0.431390134529148, 'eval_loss': 0.8402268290519714, 'eval_runtime': 42.4556, 'eval_samples_per_second': 26.263, 'eval_steps_per_second': 3.298}\", \"Lora Evaluation metrics after training: {'eval_accuracy': 0.8681614349775785, 'eval_loss': 0.30721625685691833, 'eval_runtime': 42.5423, 'eval_samples_per_second': 26.209, 'eval_steps_per_second': 3.291, 'epoch': 3.0}\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ed63_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8ed63_row3_col0\" class=\"data row3 col0\" >Run Hugging Face Evaluation</td>\n",
       "      <td id=\"T_8ed63_row3_col1\" class=\"data row3 col1\" >00:00:42.62</td>\n",
       "      <td id=\"T_8ed63_row3_col2\" class=\"data row3 col2\" >[\"Hugging Face Evaluation metrics: {'eval_loss': 0.30721625685691833, 'eval_accuracy': 0.8681614349775785, 'eval_runtime': 42.6018, 'eval_samples_per_second': 26.173, 'eval_steps_per_second': 3.286}\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ed63_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8ed63_row4_col0\" class=\"data row4 col0\" ></td>\n",
       "      <td id=\"T_8ed63_row4_col1\" class=\"data row4 col1\" >Runtime Summary</td>\n",
       "      <td id=\"T_8ed63_row4_col2\" class=\"data row4 col2\" >00:33:30.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7bc354183550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "So Long, and Thanks for All the Fish\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(resultset, columns=[\"Task\", \"Elapsed Time\", \"Result\"])\n",
    "df_styled = df.style.set_properties(**{\"text-align\": \"left\", \"white-space\": \"pre-wrap\"})  # Preserve formatting\n",
    "\n",
    "col_space_dict = {\"Task\": 30, \"Elapsed Time\": 15, \"Result\": 15}\n",
    "\n",
    "# Display in Jupyter Notebook\n",
    "display(df_styled)\n",
    "\n",
    "# Write to a fixed-width formatted text file\n",
    "output_file = \"resultset.txt\"\n",
    "text = df.to_string(index=False, col_space=col_space_dict, justify=\"left\")\n",
    "with open(output_file, \"w\") as f:\n",
    "     f.write(text)  # Fixed-width columns\n",
    "\n",
    "print(\"\\n\\n\\nSo Long, and Thanks for All the Fish\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
